{
 "cells": [
  {"cell_type": "markdown", "metadata": {}, "source": ["# ArcFace Facial Recognition Model Training\n\nEnd-to-end notebook for ArcFace-based facial recognition, from data loading and preprocessing to training, evaluation, and model saving."]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Directory & Config Setup\nSpecify dataset and output directory paths."]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import os\n# Adjust paths as needed\nDATA_ROOT = '../../dataset/images/train/'\nLABEL_ROOT = '../../dataset/labels/train/'\nMODEL_SAVE_PATH = './arcface_model.pt'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Imports"]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n# You can use a package like 'arcface-pytorch' if available for model head"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Dataset Class & DataLoader\nDefine a custom Dataset for your data layout."]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["class FaceDataset(Dataset):\n    def __init__(self, img_dir, label_dir, transform=None):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.img_names = os.listdir(img_dir)\n        self.transform = transform\n    def __len__(self):\n        return len(self.img_names)\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_names[idx])\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image)\n        # Dummy label: Modify to read actual label from file\n        label = 0\n        return image, label\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Resize((112,112))\n    # Add other augmentations if needed\n    ])\ntrain_set = FaceDataset(DATA_ROOT, LABEL_ROOT, transform=transform)\ntrain_loader = DataLoader(train_set, batch_size=32, shuffle=True)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## ArcFace Model Definition\nUse ResNet backbone and ArcFace head (implementation or from package)."]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["class ArcFaceHead(nn.Module):\n    def __init__(self, in_features, out_features, s=30.0, m=0.5):\n        super().__init__()\n        self.fc = nn.Linear(in_features, out_features, bias=False)\n        self.s = s\n        self.m = m\n    def forward(self, x, labels):\n        x_norm = nn.functional.normalize(x, p=2, dim=1)\n        w_norm = nn.functional.normalize(self.fc.weight, p=2, dim=1)\n        logits = torch.matmul(x_norm, w_norm.t())\n        if labels is not None:\n            theta = torch.acos(torch.clamp(logits, -1.0, 1.0))\n            target_logit = torch.cos(theta + self.m)\n            one_hot = torch.zeros_like(logits)\n            one_hot.scatter_(1, labels.view(-1,1), 1.0)\n            logits = logits * (1 - one_hot) + target_logit * one_hot\n        logits *= self.s\n        return logits\nbackbone = models.resnet18(pretrained=True)\nbackbone.fc = nn.Identity()\nnum_classes = 7 # angry, disgust, fear, happy, neutral, sad, surprised\narcface_head = ArcFaceHead(backbone.fc.in_features if hasattr(backbone.fc, 'in_features') else 512, num_classes)\nmodel = nn.Sequential(backbone, arcface_head).to(DEVICE)"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Training Loop"]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=1e-4)\nnum_epochs = 10\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for images, labels in train_loader:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        optimizer.zero_grad()\n        features = backbone(images)\n        logits = arcface_head(features, labels)\n        loss = criterion(logits, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    print(f'Epoch {epoch+1}/{num_epochs} Loss: {running_loss/len(train_loader):.4f}')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluation"]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["model.eval()\ncorrect, total = 0, 0\nwith torch.no_grad():\n    for images, labels in train_loader:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n        features = backbone(images)\n        logits = arcface_head(features, labels)\n        _, preds = torch.max(logits, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\nprint(f'Accuracy: {correct/total * 100:.2f}%')"]},
  {"cell_type": "markdown", "metadata": {}, "source": ["## Model Saving"]},
  {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["torch.save(model.state_dict(), MODEL_SAVE_PATH)\nprint(f'Model saved to {MODEL_SAVE_PATH}')"]}
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}